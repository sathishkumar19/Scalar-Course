{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  References\n",
    "\n",
    "- https://www.3blue1brown.com/\n",
    "- https://www.khanacademy.org/math/statistics-probability\n",
    "- https://nptel.ac.in/courses/106106139\n",
    "- https://www.slideshare.net/slideshow/nptl-machine-learning-by-madhur-jatiyapdf/257803346#2\n",
    "- https://archive.nptel.ac.in/content/syllabus_pdf/106106139.pdf\n",
    "- https://www.youtube.com/@Eigensteve   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Math Concepts to Learn \n",
    "\n",
    "#### Probability & Statistics\n",
    "\n",
    "1. Random Variables\n",
    "2. Probability Distributions\n",
    "3. Different types of Plots and distributions\n",
    "4. Population and Samples & Law of Large Numbers\n",
    "5. The Mean, Median and Expected Values\n",
    "6. Variance & Covariance, Correlation\n",
    "7. Central Limit Theorom & Normal Distribution\n",
    "8. Standard Deviation, Statistical Significance, Z- Scores & Hypothesis Testing\n",
    "9. Specificity, Sensitivity & Confusion Matrices\n",
    "10. Multiple Comparisions Problem & Solution (e.g Bonerroni Correction)\n",
    "11. Conditional Probability & Bayees Therom\n",
    "\n",
    "\n",
    "#### Linear Algebra\n",
    "\n",
    "1. Vector and Matrices\n",
    "2. Matrix Operations ( Addition, Subtractions, Multiplication, inverse, transpose)\n",
    "3. Matrix Rank and Linear Independance\n",
    "4. Basic trigonometric Terms\n",
    "\n",
    "\n",
    "#### Calculus \n",
    "1. Derivaties & thier meaning\n",
    "2. Basic rules like chain \n",
    "\n",
    "\n",
    "#### ML Specific Concepts\n",
    "\n",
    "1. Loss Functions\n",
    "2. Gradient Descent\n",
    "3. Regularization\n",
    "4. Train, Test, Validation Set\n",
    "5. Truly & Fully understand at least linear regression\n",
    "6. Labels, Weights(Parameters), Hyperparameters\n",
    "7. Validation and Cross Validation\n",
    "8. Overfitting & Underfitting\n",
    "9. IMP : Bias & Variance and Bias-Variance Tradeoff\n",
    "\n",
    "\n",
    "Source: https://www.youtube.com/watch?v=wOTFGRSUQ6Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability and Statistics Symbols\n",
    "\n",
    "- **μ (Mu)**: Pronounced \"mew\"\n",
    "    ### Probability and Statistics Symbols\n",
    "\n",
    "    | Symbol | Pronunciation | Description | Example |\n",
    "    |--------|---------------|-------------|---------|\n",
    "    | **μ**  | Mew           | Population mean | The population mean is denoted by μ. |\n",
    "    | **σ**  | Sig-ma        | Population standard deviation | The population standard deviation is denoted by σ. |\n",
    "    | **Σ**  | Sum-mation    | Summation | ΣX represents the sum of all values of X. |\n",
    "    | **π**  | Pie           | Pi | The value of π is approximately 3.14159. |\n",
    "    | **P(A)** | P of A      | Probability of A | P(A) represents the probability of event A occurring. |\n",
    "    | **E(X)** | E of X      | Expected value of X | E(X) represents the expected value of the random variable X. |\n",
    "    | **Var(X)** | Var-i-ance of X | Variance of X | Var(X) represents the variance of the random variable X. |\n",
    "    | **σ²** | Sig-ma squared | Variance | The variance of a population is denoted by σ². |\n",
    "    | **ρ**  | Row           | Correlation coefficient | ρ represents the correlation coefficient. |\n",
    "    | **α**  | Al-fa         | Level of significance | α represents the level of significance in hypothesis testing. |\n",
    "    | **β**  | Bay-ta        | Probability of Type II error | β represents the probability of Type II error in hypothesis testing. |\n",
    "    | **λ**  | Lam-da        | Rate parameter | λ represents the rate parameter in Poisson distribution. |\n",
    "    | **H₀** | H naught      | Null hypothesis | H₀ represents the null hypothesis in hypothesis testing. |\n",
    "    | **H₁** | H one         | Alternative hypothesis | H₁ represents the alternative hypothesis in hypothesis testing. |\n",
    "    | **z**  | Z score       | Z-score | The z-score represents the number of standard deviations a data point is from the mean. |\n",
    "    | **t**  | T score       | T-score | The t-score is used in t-tests to determine if there is a significant difference between groups. |\n",
    "    | **χ²** | Kai squared   | Chi-squared | The χ² test is used to determine if there is a significant association between categorical variables. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability \n",
    "\n",
    "\n",
    "| Symbol     | Pronunciation     | Description               | Example                                                         |\n",
    "|------------|-------------------|---------------------------|-----------------------------------------------------------------|\n",
    "| **A ∩ B**  | A intersection B  | Intersection of A and B   | A ∩ B represents the set of elements that are in both A and B.  |\n",
    "| **A ∪ B**  | A union B         | Union of A and B          | A ∪ B represents the set of elements that are in either A or B or both. |\n",
    "| **A \\ B**  | A minus B         | Difference of A and B     | A \\ B represents the set of elements that are in A but not in B. |\n",
    "| **A^c**    | A complement      | Complement of A           | A^c represents the set of elements that are not in A.           |\n",
    "\n",
    "When Propability kicks in \n",
    "\n",
    "| Symbol     | Pronunciation     | Description               | Example                                                         |\n",
    "|------------|-------------------|---------------------------|-----------------------------------------------------------------|\n",
    "| **P(A)**   | P of A            | Probability of A          | P(A) represents the probability of event A occurring.           |\n",
    "| **P(A ∩ B)** | P of A and B    | Probability of A and B    | P(A ∩ B) represents the probability of both events A and B occurring. |\n",
    "| **P(A ∪ B)** | P of A or B     | Probability of A or B     | P(A ∪ B) represents the probability of either event A or event B occurring. |\n",
    "| **P(A \\| B)** | P of A given B | Conditional probability   | P(A \\| B) represents the probability of event A occurring given that event B has occurred. |\n",
    "| **P(A')**  | P of A complement | Complement of A           | P(A') represents the probability of event A not occurring.      |\n",
    "| **P(A^c)** | P of A complement | Complement of A           | P(A^c) represents the probability of event A not occurring.     |\n",
    "| **P(A - B)** | P of A minus B  | Difference of A and B     | P(A - B) represents the probability of event A occurring but not event B. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "tex"
    }
   },
   "source": [
    "### Commonly Used Theorems in Probability for Machine Learning\n",
    "\n",
    "| Theorem                     | Formula                                                                 | Description |\n",
    "|-----------------------------|-------------------------------------------------------------------------|-------------|\n",
    "| **Bayes' Theorem**          | \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]                           | Describes the probability of an event based on prior knowledge of conditions related to the event. Widely used in machine learning for updating the probability of a hypothesis as more evidence becomes available. |\n",
    "| **Law of Total Probability**| \\[ P(B) = \\sum_{i} P(B|A_i) \\cdot P(A_i) \\]                             | States that the total probability of an event can be found by considering all possible ways that the event can occur. Useful in scenarios where an event can happen in multiple ways. |\n",
    "| **Chain Rule for Probabilities** | \\[ P(A_1, A_2, \\ldots, A_n) = P(A_1) \\cdot P(A_2|A_1) \\cdot P(A_3|A_1, A_2) \\cdots P(A_n|A_1, A_2, \\ldots, A_{n-1}) \\] | Allows the computation of the joint probability of a sequence of events by decomposing it into conditional probabilities. Fundamental in the construction of probabilistic models such as Bayesian networks. |\n",
    "| **Markov's Inequality**     | \\[ P(X \\geq a) \\leq \\frac{E(X)}{a} \\]                                   | Provides an upper bound on the probability that a non-negative random variable exceeds a certain value. Useful in scenarios where we need to bound the tail probabilities of distributions. |\n",
    "| **Chebyshev's Inequality**  | \\[ P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2} \\]                      | Gives an upper bound on the probability that the value of a random variable deviates from its mean by more than a certain number of standard deviations. Useful for understanding the spread of data in a distribution. |\n",
    "| **Central Limit Theorem (CLT)** | - | States that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution of the variables. Fundamental in statistics and machine learning for making inferences about population parameters. |\n",
    "| **Law of Large Numbers (LLN)** | - | States that as the number of trials or observations increases, the sample mean will converge to the expected value (population mean). Underpins many statistical methods and machine learning algorithms that rely on large datasets. |\n",
    "| **Jensen's Inequality**     | \\[ \\phi(E[X]) \\leq E[\\phi(X)] \\]                                        | States that for a convex function φ and a random variable X, the function of the expected value is less than or equal to the expected value of the function. Used in various optimization problems in machine learning. |\n",
    "\n",
    "These theorems form the foundation of many probabilistic models and algorithms used in machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Mass Function (PMF)\n",
    "\n",
    "### Central CDF\n",
    "\n",
    "### Bi"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
